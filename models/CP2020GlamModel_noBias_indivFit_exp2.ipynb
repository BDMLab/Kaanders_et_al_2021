{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cherry Picking Info: Experiment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  GLAM estimation and out of sample prediction - Individual fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Free-exploration Time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLAM model estimation/ 2nd Choice\n",
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "sufix = 'exp2_2ndChoice_Free'\n",
    "data = pd.read_csv('data/glam_data/CP2020_GlamData_CP2020_'+sufix+'.csv')\n",
    "\n",
    "# Subset only necessary columns\n",
    "data = data[['subject', 'trial', 'choice', 'rt',\n",
    "         'item_value_0', 'item_value_1',\n",
    "         'gaze_0', 'gaze_1']]\n",
    "data_len = len(data)\n",
    "print('Total number of trials: ' + str(data_len))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To run hierarchical model is required to have consecutive participant numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['subject'] = data.replace(data.subject.unique(), list(range(len(data.subject.unique()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove NaNs from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()\n",
    "print ('Percent kept: ' + str(len(data)/data_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data in training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame()\n",
    "test_data = pd.DataFrame()\n",
    "\n",
    "for subject in data.subject.unique():\n",
    "    subject_data = data[data['subject'] == subject].copy().reset_index(drop=True)\n",
    "    n_trials = len(subject_data)\n",
    "    \n",
    "    subject_train = subject_data.iloc[np.arange(0, n_trials, 2)].copy()\n",
    "    subject_test = subject_data.iloc[np.arange(1, n_trials, 2)].copy()\n",
    "\n",
    "    test_data = pd.concat([test_data, subject_test])\n",
    "    train_data = pd.concat([train_data, subject_train])\n",
    "\n",
    "#test_data.to_csv(str('data/FF2018_data/GlamDataFF2018_preprocessed_test'+sufix+'.csv'))\n",
    "#train_data.to_csv(str('data/FF2018_data/GlamDataFF2018_preprocessed_train'+sufix+'.csv'))\n",
    "\n",
    "print('Split data into training ({} trials) and test ({} trials) sets...'.format(len(train_data), len(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual GLAM estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No gaze bias ($\\gamma$ = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting full GLAM\n",
    "print('Fitting full GLAM individually...')\n",
    "\n",
    "glam_full = glam.GLAM(train_data)\n",
    "\n",
    "#if not os.path.exists(str('results/estimates/glam_FF2019_full'+sufix+'.npy')):\n",
    "glam_full.make_model('individual', gamma_val=1.0, t0_val=0)\n",
    "glam_full.fit(method='NUTS', tune=1000)\n",
    "#else:\n",
    "#    print('  Found old parameter estimates in \"results/estimates\". Skipping estimation...')\n",
    "#    glam_full.estimates = np.load(str('results/estimates/glam_FF2019_full'+sufix+'.npy'))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save parameter estimates\n",
    "np.save(str('Results/Estimates/glam_CP2020_NoBias_indiv_noBias'+sufix+'.npy'), glam_full.estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(glam_full.estimates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## estimate convergence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if glam_full.type=='hierarchical':\n",
    "\n",
    "    rhat_gamma =[] \n",
    "    rhat_v = []\n",
    "    rhat_tau =[] \n",
    "    rhat_s =[] \n",
    "    \n",
    "    rhats_params = az.rhat(glam_full.trace, method=\"folded\")\n",
    "\n",
    "    rhats_params_df = pd.DataFrame()\n",
    "    rhats_params_df['part'] = train_data.subject.unique()\n",
    "    rhats_params_df['gamma'] = rhats_params.gamma.values\n",
    "    rhats_params_df['v'] = rhats_params.v.values\n",
    "    rhats_params_df['tau'] = rhats_params.tau.values\n",
    "    rhats_params_df['s'] = rhats_params.s.values\n",
    "    \n",
    "    ess_gamma =[] \n",
    "    ess_v = []\n",
    "    ess_tau =[] \n",
    "    ess_s =[] \n",
    "    \n",
    "    ess_model = az.ess(glam_full.trace, relative=False)\n",
    "        \n",
    "    ess_params_df = pd.DataFrame()\n",
    "    ess_params_df['part'] = train_data.subject.unique()\n",
    "    ess_params_df['gamma'] = ess_model.gamma.values\n",
    "    ess_params_df['v'] = ess_model.v.values\n",
    "    ess_params_df['tau'] = ess_model.tau.values\n",
    "    ess_params_df['s'] = ess_model.s.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if glam_full.type=='individual':\n",
    "\n",
    "    rhat_gamma =[] \n",
    "    rhat_v = []\n",
    "    rhat_tau =[] \n",
    "    rhat_s =[] \n",
    "    \n",
    "    ess_gamma =[] \n",
    "    ess_v = []\n",
    "    ess_tau =[] \n",
    "    ess_s =[] \n",
    "    \n",
    "    part_num =  []\n",
    "    for i in range(len(glam_full.trace)):\n",
    "        model_trace = glam_full.trace[i]\n",
    "        # estimate rhat param\n",
    "        rhats_params = az.rhat(model_trace, method=\"folded\")\n",
    "        rhat_gamma.append(rhats_params.gamma.values)\n",
    "        rhat_v.append(rhats_params.v.values)\n",
    "        rhat_tau.append(rhats_params.tau.values)\n",
    "        rhat_s.append(rhats_params.s.values)\n",
    "        part_num.append(i)\n",
    "    \n",
    "        # estimate effective sample size\n",
    "        ess_model = az.ess(model_trace, relative=False)\n",
    "        ess_gamma.append(ess_model.gamma.values)\n",
    "        ess_v.append(ess_model.v.values)\n",
    "        ess_tau.append(ess_model.tau.values)\n",
    "        ess_s.append(ess_model.s.values)\n",
    "        \n",
    "    rhats_params_df = pd.DataFrame()\n",
    "    rhats_params_df['gamma'] = rhat_gamma\n",
    "    rhats_params_df['v'] = rhat_v\n",
    "    rhats_params_df['tau'] = rhat_tau\n",
    "    rhats_params_df['s'] = rhat_s\n",
    "    rhats_params_df['part'] = part_num\n",
    "    \n",
    "    ess_params_df = pd.DataFrame()\n",
    "    ess_params_df['gamma'] = ess_gamma\n",
    "    ess_params_df['v'] = ess_v\n",
    "    ess_params_df['tau'] = ess_tau\n",
    "    ess_params_df['s'] = ess_s\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1-rhats_params_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ess_params_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhats_params_df.to_csv(str('Results/Convergence/GlamCP2020_indiv_noBias_rhatsParams_'+sufix+'.csv'))\n",
    "ess_params_df.to_csv(str('Results/Convergence/GlamCP2020_indiv_noBias_essParams_'+sufix+'.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_params = pd.DataFrame(glam_full.estimates)\n",
    "full_params.to_csv(str('Results/ParamsEstimates/GlamCP2020_params_indiv_noBias_'+sufix+'.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## estimate WAIC scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waic_score = []\n",
    "for i in range(len(glam_full.trace)):\n",
    "    waic_score.append(pm.waic(glam_full.trace[i]).waic)\n",
    "\n",
    "np.save(str('results/waic/glam_CP2020_indiv_noBias_'+ sufix +'.npy'), waic_score)\n",
    "waic_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## estimate LOO scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loo_score = []\n",
    "for i in range(len(glam_full.trace)):\n",
    "    loo_score.append(pm.loo(glam_full.trace[i]).loo)\n",
    "\n",
    "np.save(str('Results/LOO/glam_CP2020_indiv_noBias_'+ sufix +'.npy'), loo_score)\n",
    "loo_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Predicting test set data using  GLAM...')\n",
    "glam_full.exchange_data(test_data)\n",
    "\n",
    "#if not os.path.exists(str('Results/Predictions/GlamPF2020_ind_noBias_'+sufix+'.csv')):\n",
    "glam_full.predict(n_repeats=50)\n",
    "glam_full.prediction.to_csv(str('Results/Predictions/GlamCP2020_indiv_noBias_'+sufix+'.csv'), index=False)\n",
    "#else:\n",
    "#    print('  Found old individual full GLAM predictions in \"results/predictions\". Skipping prediction...')\n",
    "#    glam_full.prediction = pd.read_csv(str('Results/Predictions/GlamPF2020_ind_noBias_'+sufix+'.csv'))\n",
    "\n",
    "glam_full.prediction.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#glam.plots_pretty_GLAM.plot_fit(test_data, [glam_full.prediction]);\n",
    "#glam.plot_fit(test_data, [glam_full.prediction,glam_nobias.prediction]);\n",
    "glam.plots_pretty_GLAM.plot_fit(test_data, [glam_full.prediction])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Fixed-exploration Time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLAM model estimation/ 2nd Choice\n",
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "sufix = 'exp2_2ndChoice_Fixed'\n",
    "data = pd.read_csv('data/glam_data/CP2020_GlamData_CP2020_'+sufix+'.csv')\n",
    "\n",
    "# Subset only necessary columns\n",
    "data = data[['subject', 'trial', 'choice', 'rt',\n",
    "         'item_value_0', 'item_value_1',\n",
    "         'gaze_0', 'gaze_1']]\n",
    "data_len = len(data)\n",
    "print('Total number of trials: ' + str(data_len))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To run hierarchical model is required to have consecutive participant numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['subject'] = data.replace(data.subject.unique(), list(range(len(data.subject.unique()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove NaNs from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()\n",
    "print ('Percent kept: ' + str(len(data)/data_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data in training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame()\n",
    "test_data = pd.DataFrame()\n",
    "\n",
    "for subject in data.subject.unique():\n",
    "    subject_data = data[data['subject'] == subject].copy().reset_index(drop=True)\n",
    "    n_trials = len(subject_data)\n",
    "    \n",
    "    subject_train = subject_data.iloc[np.arange(0, n_trials, 2)].copy()\n",
    "    subject_test = subject_data.iloc[np.arange(1, n_trials, 2)].copy()\n",
    "\n",
    "    test_data = pd.concat([test_data, subject_test])\n",
    "    train_data = pd.concat([train_data, subject_train])\n",
    "\n",
    "#test_data.to_csv(str('data/FF2018_data/GlamDataFF2018_preprocessed_test'+sufix+'.csv'))\n",
    "#train_data.to_csv(str('data/FF2018_data/GlamDataFF2018_preprocessed_train'+sufix+'.csv'))\n",
    "\n",
    "print('Split data into training ({} trials) and test ({} trials) sets...'.format(len(train_data), len(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual GLAM estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No gaze bias ($\\gamma$ = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting full GLAM\n",
    "print('Fitting full GLAM individually...')\n",
    "\n",
    "glam_full = glam.GLAM(train_data)\n",
    "\n",
    "#if not os.path.exists(str('results/estimates/glam_FF2019_full'+sufix+'.npy')):\n",
    "glam_full.make_model('individual', gamma_val=1.0, t0_val=0)\n",
    "glam_full.fit(method='NUTS', tune=1000,chains=4,cores=1)\n",
    "#else:\n",
    "#    print('  Found old parameter estimates in \"results/estimates\". Skipping estimation...')\n",
    "#    glam_full.estimates = np.load(str('results/estimates/glam_FF2019_full'+sufix+'.npy'))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save parameter estimates\n",
    "np.save(str('Results/Estimates/glam_CP2020_NoBias_indiv_noBias'+sufix+'.npy'), glam_full.estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(glam_full.estimates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## estimate convergence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if glam_full.type=='hierarchical':\n",
    "\n",
    "    rhat_gamma =[] \n",
    "    rhat_v = []\n",
    "    rhat_tau =[] \n",
    "    rhat_s =[] \n",
    "    \n",
    "    rhats_params = az.rhat(glam_full.trace, method=\"folded\")\n",
    "\n",
    "    rhats_params_df = pd.DataFrame()\n",
    "    rhats_params_df['part'] = train_data.subject.unique()\n",
    "    rhats_params_df['gamma'] = rhats_params.gamma.values\n",
    "    rhats_params_df['v'] = rhats_params.v.values\n",
    "    rhats_params_df['tau'] = rhats_params.tau.values\n",
    "    rhats_params_df['s'] = rhats_params.s.values\n",
    "    \n",
    "    ess_gamma =[] \n",
    "    ess_v = []\n",
    "    ess_tau =[] \n",
    "    ess_s =[] \n",
    "    \n",
    "    ess_model = az.ess(glam_full.trace, relative=False)\n",
    "        \n",
    "    ess_params_df = pd.DataFrame()\n",
    "    ess_params_df['part'] = train_data.subject.unique()\n",
    "    ess_params_df['gamma'] = ess_model.gamma.values\n",
    "    ess_params_df['v'] = ess_model.v.values\n",
    "    ess_params_df['tau'] = ess_model.tau.values\n",
    "    ess_params_df['s'] = ess_model.s.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if glam_full.type=='individual':\n",
    "\n",
    "    rhat_gamma =[] \n",
    "    rhat_v = []\n",
    "    rhat_tau =[] \n",
    "    rhat_s =[] \n",
    "    \n",
    "    ess_gamma =[] \n",
    "    ess_v = []\n",
    "    ess_tau =[] \n",
    "    ess_s =[] \n",
    "    \n",
    "    part_num =  []\n",
    "    for i in range(len(glam_full.trace)):\n",
    "        model_trace = glam_full.trace[i]\n",
    "        # estimate rhat param\n",
    "        rhats_params = az.rhat(model_trace, method=\"folded\")\n",
    "        rhat_gamma.append(rhats_params.gamma.values)\n",
    "        rhat_v.append(rhats_params.v.values)\n",
    "        rhat_tau.append(rhats_params.tau.values)\n",
    "        rhat_s.append(rhats_params.s.values)\n",
    "        part_num.append(i)\n",
    "    \n",
    "        # estimate effective sample size\n",
    "        ess_model = az.ess(model_trace, relative=False)\n",
    "        ess_gamma.append(ess_model.gamma.values)\n",
    "        ess_v.append(ess_model.v.values)\n",
    "        ess_tau.append(ess_model.tau.values)\n",
    "        ess_s.append(ess_model.s.values)\n",
    "        \n",
    "    rhats_params_df = pd.DataFrame()\n",
    "    rhats_params_df['gamma'] = rhat_gamma\n",
    "    rhats_params_df['v'] = rhat_v\n",
    "    rhats_params_df['tau'] = rhat_tau\n",
    "    rhats_params_df['s'] = rhat_s\n",
    "    rhats_params_df['part'] = part_num\n",
    "    \n",
    "    ess_params_df = pd.DataFrame()\n",
    "    ess_params_df['gamma'] = ess_gamma\n",
    "    ess_params_df['v'] = ess_v\n",
    "    ess_params_df['tau'] = ess_tau\n",
    "    ess_params_df['s'] = ess_s\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1-rhats_params_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ess_params_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhats_params_df.to_csv(str('Results/Convergence/GlamCP2020_indiv_noBias_rhatsParams_'+sufix+'.csv'))\n",
    "ess_params_df.to_csv(str('Results/Convergence/GlamCP2020_indiv_noBias_essParams_'+sufix+'.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_params = pd.DataFrame(glam_full.estimates)\n",
    "full_params.to_csv(str('Results/ParamsEstimates/GlamCP2020_params_indiv_noBias_'+sufix+'.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## estimate WAIC scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waic_score = []\n",
    "for i in range(len(glam_full.trace)):\n",
    "    waic_score.append(pm.waic(glam_full.trace[i]).waic)\n",
    "\n",
    "np.save(str('results/waic/glam_CP2020_indiv_noBias_'+ sufix +'.npy'), waic_score)\n",
    "waic_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## estimate LOO scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loo_score = []\n",
    "for i in range(len(glam_full.trace)):\n",
    "    loo_score.append(pm.loo(glam_full.trace[i]).loo)\n",
    "\n",
    "np.save(str('Results/LOO/glam_CP2020_indiv_noBias_'+ sufix +'.npy'), loo_score)\n",
    "loo_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Predicting test set data using  GLAM...')\n",
    "glam_full.exchange_data(test_data)\n",
    "\n",
    "#if not os.path.exists(str('Results/Predictions/GlamPF2020_ind_noBias_'+sufix+'.csv')):\n",
    "glam_full.predict(n_repeats=50)\n",
    "glam_full.prediction.to_csv(str('Results/Predictions/GlamCP2020_indiv_noBias_'+sufix+'.csv'), index=False)\n",
    "#else:\n",
    "#    print('  Found old individual full GLAM predictions in \"results/predictions\". Skipping prediction...')\n",
    "#    glam_full.prediction = pd.read_csv(str('Results/Predictions/GlamPF2020_ind_noBias_'+sufix+'.csv'))\n",
    "\n",
    "glam_full.prediction.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#glam.plots_pretty_GLAM.plot_fit(test_data, [glam_full.prediction]);\n",
    "#glam.plot_fit(test_data, [glam_full.prediction,glam_nobias.prediction]);\n",
    "glam.plots_pretty_GLAM.plot_fit(test_data, [glam_full.prediction])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import toolboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glam\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "import arviz as az\n",
    "import seaborn as sns\n",
    "from IPython.core.pylabtools import figsize\n",
    "from sklearn import linear_model  # packages for the logistic regression function to plot the logistic regression \n",
    "from sklearn.linear_model import LogisticRegression # \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pymc3 as pm\n",
    "\n",
    "np.random.seed(23) # from random.org\n",
    "\n",
    "def logisticplot_simpl (modlow, data, xaxis='zDV', yaxis='G_choice', ylab='P(Chose Reference Item)', xlab='DV (Z-score)',\n",
    "                  modlowcol='#AAAAAA', title='empty', xlim = [-5,5]):\n",
    "    \n",
    "    sns.set(font_scale=1.5, style='white')\n",
    "    figsize(5,5)\n",
    "    \n",
    "    # defining the sigmoid function\n",
    "    def model(x):\n",
    "        y = 1 / (1 + np.exp(-x))\n",
    "        return y\n",
    "    \n",
    "    sub = plt.subplot()\n",
    "\n",
    "\n",
    "    #run the classifier\n",
    "    clf = linear_model.LogisticRegression(C=1e5)\n",
    "\n",
    "    logit_low = {}\n",
    "\n",
    "    # I think this defines the problem space\n",
    "    X_test = np.linspace(-10,10,300)\n",
    "\n",
    "    # fitting the predictive logistic model for the low_confidence trials, for a participant specified by x\n",
    "    # first I specify the value difference right - left, then I specify the choices, left or right\n",
    "    clf.fit(data[xaxis][:, np.newaxis],\n",
    "            data [yaxis])\n",
    "    logit_low = model(X_test*clf.coef_ + clf.intercept_).ravel()\n",
    "    print ('Low measure coef',clf.coef_)\n",
    "    \n",
    "    #Plotting the predictive lines\n",
    "    line_low = sub.plot(X_test, logit_low, color=modlowcol, linewidth=5, label=modlow, zorder=5) \n",
    "    \n",
    "    # Set Labels\n",
    "    sub.set_ylabel(ylab, fontsize=30)\n",
    "    sub.set_xlabel(xlab, fontsize=30)\n",
    "\n",
    "    # Set Ticks\n",
    "    sub.set_xticks((-5,-3,-1,1,3,5))\n",
    "    sub.set_yticks((0,0.25,0.5,0.75,1))\n",
    "    sub.tick_params(axis='both', which='major', labelsize=20)\n",
    "\n",
    "    # Set Limits\n",
    "    sub.set_ylim(-0.01, 1.01)\n",
    "    sub.set_xlim(xlim[0], xlim[1])\n",
    "\n",
    "    # Set Title\n",
    "    if title == 'empty':\n",
    "        sub.set_title('')\n",
    "    else:\n",
    "        sub.set_title(title)\n",
    "    \n",
    "    sub.legend(loc=0, prop={'size':20})\n",
    "    \n",
    "    sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [END] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
